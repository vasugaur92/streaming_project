version: "3.9"

services:
  # --------------------------------------------------
  # KAFKA (KRaft mode - no Zookeeper)
  # --------------------------------------------------
  kafka-broker:
    image: apache/kafka:latest
    container_name: kafka-broker
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "controller,broker"

      # Important: listeners CANNOT be split across lines
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,PLAINTEXT_DOCKER://0.0.0.0:29092,CONTROLLER://0.0.0.0:9093"

      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://localhost:9092,PLAINTEXT_DOCKER://kafka-broker:29092"

      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,PLAINTEXT_DOCKER:PLAINTEXT,CONTROLLER:PLAINTEXT"

      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-broker:9093"

      # REQUIRED for KRaft single node:
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_DOCKER

      # Single-node replication settings
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 1

  # --------------------------------------------------
  # SPARK MASTER
  # --------------------------------------------------
  spark-master:
    image: apache/spark:4.0.1
    container_name: spark-master
    command: [ "/opt/spark/bin/spark-class", "org.apache.spark.deploy.master.Master" ]
    environment:
      SPARK_MASTER_HOST: spark-master
      HOME: /opt/spark
      SPARK_SUBMIT_OPTS: "-Dspark.jars.ivy=/tmp/.ivy2"
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./spark_streaming:/opt/spark/spark_streaming # <-- updated folder mount
    depends_on:
      - kafka-broker

  # --------------------------------------------------
  # SPARK WORKER
  # --------------------------------------------------
  spark-worker:
    image: apache/spark:4.0.1
    container_name: spark-worker
    command: [ "/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077" ]
    ports:
      - "8081:8081"
    environment:
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 2G
      HOME: /opt/spark
      SPARK_SUBMIT_OPTS: "-Dspark.jars.ivy=/tmp/ivy"
    volumes:
      - ./spark_streaming:/opt/spark/spark_streaming # <-- updated folder mount
    depends_on:
      - spark-master
      - kafka-broker
